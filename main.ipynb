{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Libaries\n",
    "'''\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset\n",
    "'''\n",
    "\n",
    "class EICDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return super().__getitem__(index)\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Collator(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model\n",
    "'''\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hyper parameters\n",
    "'''\n",
    "random_seed = 42\n",
    "max_len = 64\n",
    "batch_size = 4\n",
    "epochs = 20\n",
    "lr = 2e-5\n",
    "device = 'cuda:0'\n",
    "checkpoint_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Environment setup\n",
    "'''\n",
    "# random seed\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "train_data = EICDataset()\n",
    "dev_data = EICDataset()\n",
    "test_data = EICDataset()\n",
    "\n",
    "collator = Collator()\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, collate_fn=collator)\n",
    "dev_loader = DataLoader(dev_data, batch_size = batch_size, collate_fn=collator)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, collate_fn=collator)\n",
    "\n",
    "model = MyModel().to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training loop\n",
    "'''\n",
    "best_ckp = None\n",
    "best_loss = np.inf\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    loss_accum = 0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(train_loader, desc=\"Epoch {}\".format(epoch))):\n",
    "\n",
    "        for key in batch[0].keys():\n",
    "            batch[0][key] = batch[0][key].to(device)\n",
    "\n",
    "        pred = model(batch[0])\n",
    "        #print(pred, batch[1])\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(pred, batch[1].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_accum += loss.detach().cpu().item()\n",
    "\n",
    "    train_loss = loss_accum / (step + 1)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_accum = 0\n",
    "    for step, batch in enumerate(tqdm(dev_loader, desc=\"Dev\")):\n",
    "\n",
    "        for key in batch[0].keys():\n",
    "            batch[0][key] = batch[0][key].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch[0])\n",
    "\n",
    "        loss = criterion(pred, batch[1].to(device))\n",
    "\n",
    "        loss_accum += loss.detach().cpu().item()\n",
    "\n",
    "    dev_loss = loss_accum / (step + 1)\n",
    "    \n",
    "    if dev_loss < best_loss:\n",
    "        best_loss = dev_loss\n",
    "        checkpoint = {'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'scheduler_state_dict': scheduler.state_dict(), 'best_val_metric': best_loss}\n",
    "        best_ckp = os.path.join(checkpoint_dir, 'checkpoint.pt')\n",
    "        torch.save(checkpoint, os.path.join(checkpoint_dir, 'checkpoint.pt'))\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f'Best validation metric so far: {best_loss}, Latest Lr: {scheduler.get_last_lr()[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Give test results\n",
    "'''\n",
    "ids = []\n",
    "res = []\n",
    "model.load_state_dict(torch.load(best_ckp)['model_state_dict'])\n",
    "model.eval()\n",
    "for step, batch in enumerate(tqdm(test_loader, desc=\"Test\")):\n",
    "\n",
    "    for key in batch[0].keys():\n",
    "        batch[0][key] = batch[0][key].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(batch[0])\n",
    "\n",
    "    res.append(pred)\n",
    "\n",
    "with open('./output.csv', 'w+', encoding='utf-8') as f:\n",
    "    f.write('id\\tpred\\n')\n",
    "    for item in zip(ids, res):\n",
    "        f.write(item[0] + '\\t' + item[1] + '\\n')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
