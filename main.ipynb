{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Libaries\n",
    "'''\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset\n",
    "'''\n",
    "\n",
    "def filter(text):\n",
    "    pattern = re.compile(\"[^.^!^?^'^ ^a-z^A-Z^0-9]\")\n",
    "    text = pattern.sub('', text)\n",
    "\n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "    text = re.sub(\"''+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "class Cleaner(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, text):\n",
    "        text = re.sub(r'-', ' ', text)\n",
    "        text = re.sub(r\"$NEWLINE$\", \" \", text)\n",
    "        text = re.sub(r\"NEWLINE\", \" \", text)\n",
    "\n",
    "        # remove urls\n",
    "        text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', ' ', text)\n",
    "        # remove @somebody\n",
    "        text = re.sub(r\"@\\S+\", \"\", text)\n",
    "\n",
    "        # remove #topic\n",
    "        text = re.sub(r\"#\\S+\", \"\", text)\n",
    "\n",
    "        # clean unrecognizable characters\n",
    "        text = filter(text)\n",
    "\n",
    "        # text = text.lower()\n",
    "        text = re.sub(\" +\", \" \", text)\n",
    "\n",
    "        return text.strip()\n",
    "\n",
    "class EICDataset(Dataset):\n",
    "    def __init__(self, path, mode):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.data = pd.read_csv(path)\n",
    "        self.original = []\n",
    "        self.edited = []\n",
    "        cleaner = Cleaner()\n",
    "        for i in range(0, len(self.data)):\n",
    "            temp = self.data['original'][i]\n",
    "            self.original.append(cleaner(temp))\n",
    "            temp = re.sub('<.*/>', self.data['edit'][i], temp)\n",
    "            self.edited.append(cleaner(temp))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train' or self.mode == 'dev':\n",
    "            return self.data['id'][index], self.original[index], self.edited[index], self.data['meanGrade'][index]\n",
    "        else:\n",
    "            return self.data['id'][index], self.original[index], self.edited[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "class Collator(object):\n",
    "    def __init__(self, tokenizer, max_len, mode):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        passages = [ex[1] for ex in batch]\n",
    "        passages = self.tokenizer.batch_encode_plus(\n",
    "            passages,\n",
    "            max_length=self.max_len if self.max_len > 0 else None,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt',\n",
    "            truncation=True if self.max_len > 0 else False,)\n",
    "\n",
    "        if self.mode == 'train' or self.mode == 'dev':\n",
    "            targets = torch.tensor([ex[3] for ex in batch]).float()\n",
    "            return passages, targets\n",
    "        else:\n",
    "            return passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model\n",
    "'''\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        outputs = self.bert(**input) \n",
    "        pooled_output = outputs[1] # B x 768\n",
    "        logits = self.linear(pooled_output) # B x 1\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Hyper parameters\n",
    "'''\n",
    "random_seed = 42\n",
    "max_len = 64\n",
    "batch_size = 4\n",
    "epochs = 20\n",
    "lr = 2e-5\n",
    "device = 'cuda:0'\n",
    "checkpoint_dir = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Environment setup\n",
    "'''\n",
    "# random seed\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "tk = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_data = EICDataset('./Dataset/train.csv', 'train')\n",
    "dev_data = EICDataset('./Dataset/dev.csv', 'dev')\n",
    "test_data = EICDataset('./Dataset/test.csv', 'test')\n",
    "\n",
    "label_collator = Collator(tk, max_len, 'train')\n",
    "test_collator = Collator(tk, max_len, 'test')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, collate_fn=label_collator)\n",
    "dev_loader = DataLoader(dev_data, batch_size = batch_size, collate_fn=label_collator)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, collate_fn=test_collator)\n",
    "\n",
    "model = MyModel().to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/2413 [00:00<?, ?it/s]c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch 1: 100%|██████████| 2413/2413 [02:35<00:00, 15.55it/s]\n",
      "Dev:  99%|█████████▉| 598/605 [00:07<00:00, 96.80it/s]c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Dev: 100%|██████████| 605/605 [00:07<00:00, 84.32it/s]\n",
      "Epoch 2:   0%|          | 2/2413 [00:00<02:27, 16.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation metric so far: 0.33419485081695327, Latest Lr: 2e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  18%|█▊        | 442/2413 [00:27<02:02, 16.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-4447f65b234a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Training loop\n",
    "'''\n",
    "best_ckp = None\n",
    "best_loss = np.inf\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    loss_accum = 0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(train_loader, desc=\"Epoch {}\".format(epoch))):\n",
    "\n",
    "        for key in batch[0].keys():\n",
    "            batch[0][key] = batch[0][key].to(device)\n",
    "\n",
    "        pred = model(batch[0])\n",
    "        #print(pred, batch[1])\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(pred, batch[1].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_accum += loss.detach().cpu().item()\n",
    "\n",
    "    train_loss = loss_accum / (step + 1)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_accum = 0\n",
    "    for step, batch in enumerate(tqdm(dev_loader, desc=\"Dev\")):\n",
    "\n",
    "        for key in batch[0].keys():\n",
    "            batch[0][key] = batch[0][key].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch[0])\n",
    "\n",
    "        loss = criterion(pred, batch[1].to(device))\n",
    "\n",
    "        loss_accum += loss.detach().cpu().item()\n",
    "\n",
    "    dev_loss = loss_accum / (step + 1)\n",
    "    print(f'Current Train Loss: {train_loss}, Current Dev Loss: {dev_loss}, Latest Lr: {scheduler.get_last_lr()[0]}')\n",
    "    \n",
    "    if dev_loss < best_loss:\n",
    "        best_loss = dev_loss\n",
    "        checkpoint = {'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'scheduler_state_dict': scheduler.state_dict(), 'best_val_metric': best_loss}\n",
    "        best_ckp = os.path.join(checkpoint_dir, 'checkpoint.pt')\n",
    "        torch.save(checkpoint, os.path.join(checkpoint_dir, 'checkpoint.pt'))\n",
    "        print(f'Best validation metric so far: {best_loss}')\n",
    "\n",
    "    scheduler.step()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Give test results\n",
    "'''\n",
    "ids = []\n",
    "res = []\n",
    "model.load_state_dict(torch.load(best_ckp)['model_state_dict'])\n",
    "model.eval()\n",
    "for step, batch in enumerate(tqdm(test_loader, desc=\"Test\")):\n",
    "\n",
    "    for key in batch[0].keys():\n",
    "        batch[0][key] = batch[0][key].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(batch[0])\n",
    "\n",
    "    res.append(pred)\n",
    "\n",
    "with open('./output.csv', 'w+', encoding='utf-8') as f:\n",
    "    f.write('id\\tpred\\n')\n",
    "    for item in zip(ids, res):\n",
    "        f.write(item[0] + '\\t' + item[1] + '\\n')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
